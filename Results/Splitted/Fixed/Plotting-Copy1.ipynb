{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "94ab086b-7330-4f6c-8106-b14ac3ef375b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 born_method\n",
      "1 history_of_periodontiti\n",
      "2 disease_subtype\n",
      "3 udy_condition\n",
      "4 ORR\n",
      "5 ever_smoker\n",
      "6 PFS12\n",
      "7 birth_order\n",
      "8 country\n",
      "9 feeding_practice\n",
      "10 non_westernized\n",
      "11 age_category\n",
      "12 family_role\n",
      "13 location\n",
      "14 uncurated_metadata\n",
      "15 gender\n",
      "16 body_site\n",
      "17 birth_control_pil\n",
      "18 moker\n",
      "19 dental_sample_type\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "502e6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analysis(values, thr=0.05):\n",
    "    # print(values)\n",
    "    better = []\n",
    "    comparable = []\n",
    "    thr = 0.05 \n",
    "\n",
    "    last_value = values[4]\n",
    "    \n",
    "    for v in values[0:4]:\n",
    "        # print(v)\n",
    "        better.append(round(last_value -v, 2) > thr)\n",
    "        comparable.append(abs(round(last_value -v, 2)) <= thr)\n",
    "\n",
    "    if all(better):\n",
    "        return (True, 'better_all' )\n",
    "    elif True in better:\n",
    "        return (True, 'better_one' )\n",
    "    elif all( comparable):\n",
    "        return (True, 'Comp_with_all' )\n",
    "    elif True in comparable:\n",
    "        return (True, 'Comp_with_one' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8d20cf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'better_one')"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analysis([0.58, 0.61, 0.63, 0.61, 0.66], thr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "67856b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "color_scale=[\n",
    "    [0, 'green'],    # Value -1 will be red\n",
    "    [0.5, 'red'], # Value 0 will be yellow\n",
    "    [1, 'yellow']    # Value 1 will be blue\n",
    "]\n",
    "\n",
    "# Define the color scale constant\n",
    "COLOR_SCALE = {\n",
    "    'Comp_with_all': 'cyan',\n",
    "    'better_all': 'violet',\n",
    "    'Comp_with_one': 'black',\n",
    "    'better_one': 'red'\n",
    "}\n",
    "\n",
    "def ResultSummary(file):\n",
    "    # print(file)\n",
    "    new_DF = pd.read_csv(file, sep='\\t')\n",
    "    new_DF.set_index('name', inplace=True)\n",
    "\n",
    "    DF = new_DF.T\n",
    "    DF.columns = new_DF.index\n",
    "    DF.index = new_DF.columns\n",
    "    df = DF.iloc[[0, 5, 10, 15, 20]]\n",
    "\n",
    "    column_anno_per = {}\n",
    "    comparable = {}\n",
    "\n",
    "    # print(df.columns)\n",
    "\n",
    "    for n in df.columns.to_list():\n",
    "        # print(n, df[n].values)\n",
    "        comparable[n] = Analysis(df[n].values, threshold)\n",
    "    return comparable\n",
    "\n",
    "def Plot(number, width=300, height=400):\n",
    "    input_file = fs[number]\n",
    "    # print(input_file)\n",
    "    threshold = 0.05\n",
    "\n",
    "    result_1 = ResultSummary(input_file)\n",
    "\n",
    "    true_columns = []\n",
    "    true_column_comp = []\n",
    "\n",
    "    for i, k in enumerate(result_1.keys()):\n",
    "        if result_1[k]:\n",
    "            true_column_comp.append((i, result_1[k], k))\n",
    "\n",
    "    plotting_columns = {\n",
    "        'Comp_with_all': [],\n",
    "        'better_all': [],\n",
    "        'Comp_with_one': [],\n",
    "        'better_one': [],\n",
    "        'None': [],\n",
    "    }\n",
    "\n",
    "    colors = COLOR_SCALE\n",
    "    arranged_columns = []\n",
    "    counter = 0\n",
    "\n",
    "    for c in colors.keys():\n",
    "        for i, a in enumerate(true_column_comp):\n",
    "            if c == a[1][1]:\n",
    "                counter += 1\n",
    "                plotting_columns[c].append((a[2], counter - 1))\n",
    "                arranged_columns.append(a[2])\n",
    "\n",
    "    # DF = pd.read_csv(input_file, sep='\\t')\n",
    "    # DF.set_index('name', inplace=True)\n",
    "\n",
    "    new_DF = pd.read_csv(input_file, sep='\\t')\n",
    "    new_DF.set_index('name', inplace=True)\n",
    "\n",
    "    DF = new_DF.T\n",
    "    DF.columns = new_DF.index\n",
    "    DF.index = new_DF.columns\n",
    "    df = DF.iloc[[0, 5, 10, 15, 20]]  # Acc\n",
    "    df = df[arranged_columns]\n",
    "\n",
    "    df.index.name = 'name'\n",
    "\n",
    "    heatmap = go.Heatmap(\n",
    "        z=df.values,\n",
    "        x=df.columns,\n",
    "        # zmin=-1,\n",
    "        # zmax=1,\n",
    "        y=['LRC', 'DTC', 'SVC', 'RFC', 'HDC'],\n",
    "        # colorbar=dict(title='Value'),\n",
    "        text=df.values,  # Display values in each cell\n",
    "        texttemplate=\"%{text}\",  # Format for text\n",
    "        textfont=dict(color='white'),  # Ensure text is visible on darker colors\n",
    "        colorscale='Portland'  \n",
    "        # colorscale=color_scale \n",
    "    )\n",
    "\n",
    "    shapes = []\n",
    "\n",
    "    for i in range(5, len(df), 5):\n",
    "        shapes.append(\n",
    "            go.layout.Shape(\n",
    "                type='line',\n",
    "                x0=-0.5,\n",
    "                x1=len(df.columns) - 0.5,\n",
    "                y0=i - 0.5,\n",
    "                y1=i - 0.5,\n",
    "                line=dict(color='white', width=2),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    ind = 0\n",
    "    for t in plotting_columns.keys():\n",
    "        if t != 'None' and len(plotting_columns[t]) > 0:\n",
    "            col_idx = plotting_columns[t][0][1]\n",
    "            row_idx = 4\n",
    "            shape1 = go.layout.Shape(\n",
    "                type='rect',\n",
    "                x0=col_idx - 0.48,\n",
    "                x1=plotting_columns[t][-1][1] + 0.48,\n",
    "                y0=row_idx - 4.5,\n",
    "                y1=row_idx + 0.5,\n",
    "                line=dict(color=colors[t], width=3),  # Use color from the color scale constant\n",
    "                fillcolor='rgba(255, 255, 255, 0)',  # Transparent fill\n",
    "            )\n",
    "            shapes.append(shape1)\n",
    "\n",
    "    fig = go.Figure(data=[heatmap])\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=width,\n",
    "        height=height,\n",
    "        shapes=shapes,\n",
    "        title=input_file,\n",
    "        xaxis=dict(title='Metrics'),\n",
    "        yaxis=dict(title='Rows'),\n",
    "        yaxis_autorange='reversed',\n",
    "        # colorscale=[[1, 'blue'], [-1, 'red']],\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "87a32836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 born_method\n",
      "1 history_of_periodontiti\n",
      "2 disease_subtype\n",
      "3 udy_condition\n",
      "4 ORR\n",
      "5 ever_smoker\n",
      "6 PFS12\n",
      "7 birth_order\n",
      "8 country\n",
      "9 feeding_practice\n",
      "10 non_westernized\n",
      "11 age_category\n",
      "12 family_role\n",
      "13 location\n",
      "14 uncurated_metadata\n",
      "15 gender\n",
      "16 body_site\n",
      "17 birth_control_pil\n",
      "18 moker\n",
      "19 dental_sample_type\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "fs = glob.glob('../../ResultsSelectedMin200Samples/CombinedResults100/Splitted/*.tsv')\n",
    "for i, f in enumerate(fs):\n",
    "    print(i, f.split('/')[5].strip('.tsv'))\n",
    "\n",
    "# Error fix\n",
    "# Data Stats\n",
    "# Color blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "950899aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Plot() missing 2 required positional arguments: 'width' and 'height'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[274], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mPlot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Plot() missing 2 required positional arguments: 'width' and 'height'"
     ]
    }
   ],
   "source": [
    "Plot(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb207145-dc0b-45ee-a174-9440da62ebf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body_subsite.tsv'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig.write_image(input_file.split('.')[0]+'_ACC.svg', format=\"svg\")\n",
    "input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb645597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Analysis(values, threshold=0.05):\n",
    "    better = []\n",
    "    comparable = []\n",
    "    thr = 0.05 \n",
    "\n",
    "    last_value = values[4]\n",
    "\n",
    "    for v in values[0:4]:\n",
    "        better.append(round(last_value -v, 2) > threshold)\n",
    "        comparable.append(abs(round(last_value -v, 2)) <= threshold)\n",
    "\n",
    "    if all(better):\n",
    "        return (True, 'better_all' )\n",
    "    elif True in better:\n",
    "        return (True, 'better_one' )\n",
    "    elif all( comparable):\n",
    "        return (True, 'Comp_with_all' )\n",
    "    elif True in comparable:\n",
    "        return (True, 'Comp_with_one' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1d9beb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age_category',\n",
       " 'birth_control_pil',\n",
       " 'birth_order',\n",
       " 'body_site',\n",
       " 'born_method',\n",
       " 'country',\n",
       " 'disease_subtype',\n",
       " 'ever_smoker',\n",
       " 'family_role',\n",
       " 'gender',\n",
       " 'location',\n",
       " 'study_condition',\n",
       " 'uncurated_metadata'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !ls ../../MicroBiomML/datasets-ra/\n",
    "import numpy as np\n",
    "data_file = glob.glob('../../MicroBiomML/datasets-ra/*.tsv')\n",
    "\n",
    "cut_off = 200\n",
    "\n",
    "refined_catogories = []\n",
    "\n",
    "f = open('../../ResultsSelectedMin200Samples/selected_data_'+str(cut_off)+'_Samples_or_more.txt', 'w')\n",
    "\n",
    "for d in data_file:\n",
    "    df = pd.read_csv(d, sep=\"\\t\")\n",
    "    label_counts = df['label'].value_counts()\n",
    "    count_values = label_counts.values\n",
    "    if df.shape[0] >= cut_off:\n",
    "    # print(d.split('/')[4].split('.')[1],df.shape[0], count_values[0], df.shape[0]/count_values[0])\n",
    "    # print(d.split('/')[4].split('.')[1],df.shape[0], count_values[1], df.shape[0]/count_values[1])\n",
    "        # print(d.split('/')[4], np.array([df.shape[0]/count_values[0], df.shape[0]/count_values[1]]).max(), df.shape[0], count_values[0], count_values[1] )\n",
    "        refined_catogories.append(d.split('/')[4].split('.')[3])\n",
    "        f.write(d.split('/')[4]+'\\n')\n",
    "    # print(d.split('/')[4].split('.')[1],df.shape[0], count_values[0], count_values[1], (count_values[0]+count_values[1])/2, (df.shape[0])/(count_values[0])+(df.shape[0])/(count_values[1])/2 )\n",
    "\n",
    "f.close()\n",
    "set(refined_catogories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7e530a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off  = 200\n",
    "f = open('../../ResultsSelectedMin200Samples/selected_data_'+str(cut_off)+'_Samples_or_more.txt')\n",
    "selected_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5abacc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n",
      "#######################\n",
      "LRC\n",
      "DTC\n",
      "SVC\n",
      "RFC\n"
     ]
    }
   ],
   "source": [
    "out_file = open('../../ResultsSelectedMin200Samples/merged_results_'+str(cut_off)+'.tsv', 'w')\n",
    "\n",
    "header = ['Acc_LRC','F1_LRC','Prec_LRC','Recall_LRC','MCC_LRC', 'Acc_DTC','F1_DTC','Prec_DTC','Recall_DTC','MCC_DTC', 'Acc_SVC','F1_SVC','Prec_SVC','Recall_SVC','MCC_SVC', 'Acc_RFC','F1_RFC','Prec_RFC','Recall_RFC','MCC_RFC','Acc_HDC','F1_HDC','Prec_HDC','Recall_HDC','MCC_HDC']\n",
    "header = '\\t'.join(header)\n",
    "\n",
    "out_file.write('name'+'\\t'+header+'\\n')\n",
    "\n",
    "def return_hdc_data(file_name):\n",
    "    f = open('../../MicroBiomML/hdlib-ra-levels1000-retrain20-cv5-feature-selection/HDC_result_files/'+file_name+'.txt')\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'Total elapsed time:' in line:\n",
    "            result = [f\"{float(lines[i-5].split(' ')[1]):.2f}\",  f\"{float(lines[i-4].split(' ')[1]):.2f}\", f\"{float(lines[i-3].split(' ')[1]):.2f}\", f\"{float(lines[i-2].split(' ')[1]):.2f}\", f\"{float(lines[i-1].split(' ')[3]):.2f}\"]\n",
    "    return result\n",
    "\n",
    "fs = glob.glob('./datasets-ra/*.tsv')\n",
    "\n",
    "algs = ['LRC', 'DTC', 'SVC', 'RFC']\n",
    "\n",
    "for d in selected_lines:\n",
    "    d = d.strip('\\n')\n",
    "\n",
    "    result_list = []\n",
    "    print(\"#######################\")\n",
    "    for alg in algs:\n",
    "        data =  open(os.path.join('../../', alg+\"_results\", 'result.tsv'))\n",
    "        lines = data.readlines()\n",
    "        print(alg)\n",
    "        for i in lines:\n",
    "            if d in i:\n",
    "                result_list = result_list + i.rstrip('\\n').split(',')[1:]\n",
    "    result_list =  [f\"{float(v):.2f}\" for v in result_list]\n",
    "    \n",
    "    result = return_hdc_data(d)\n",
    "    out_file.write(d+'\\t'+'\\t'.join(result_list+result)+'\\n')\n",
    "out_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "88a3c24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshij/Desktop/Classification_5_06_24/Splitted/Fixed\n",
      "Analysis_with_mean.ipynb     dental_sample_type.tsv\n",
      "Analysis_without_mean.ipynb  disease_subtype.tsv\n",
      "\u001b[34mFixed\u001b[m\u001b[m                        ever_smoker.tsv\n",
      "MeanEx.py                    family_role.tsv\n",
      "ORR.tsv                      feeding_practice.tsv\n",
      "PFS12.tsv                    gender.tsv\n",
      "Untitled.ipynb               history_of_periodontitis.tsv\n",
      "Untitled1.ipynb              location.tsv\n",
      "Untitled2.ipynb              non_westernized.tsv\n",
      "age_category.tsv             plot.py\n",
      "alcohol.tsv                  remission.tsv\n",
      "anti_PD_1.tsv                scatter_plot.svg\n",
      "birth_control_pil.tsv        shigatoxin_2_elisa.tsv\n",
      "birth_order.tsv              smoker.tsv\n",
      "body_site.tsv                split_results.py\n",
      "body_subsite.tsv             study_condition.tsv\n",
      "born_method.tsv              treatment.tsv\n",
      "country.tsv                  uncurated_metadata.tsv\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6eb55f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../../ResultsSelectedMin200Samples/CombinedResults200/merged_results_200.tsv')\n",
    "\n",
    "lines = f.readlines()\n",
    "category =  list(set([ line.split('\\t')[0].split('.')[3] for line in lines[1:] ]))\n",
    "\n",
    "'LRC', 'DTC', 'LRC', 'RFC'\n",
    "\n",
    "header = ['Acc_LRC','F1_LRC','Prec_LRC','Recall_LRC','MCC_LRC', 'Acc_DTC','F1_DTC','Prec_DTC','Recall_DTC','MCC_DTC', 'Acc_SVC','F1_SVC','Prec_SVC','Recall_SVC','MCC_SVC', 'Acc_RFC','F1_RFC','Prec_RFC','Recall_RFC','MCC_RFC','Acc_HDC','F1_HDC','Prec_HDC','Recall_HDC','MCC_HDC']\n",
    "header = '\\t'.join(header)\n",
    "\n",
    "\n",
    "for c in category:\n",
    "    out = open('../../ResultsSelectedMin200Samples/CombinedResults200/Splitted/'+c+'.tsv', 'w')\n",
    "    out.write('name'+'\\t'+header+'\\n')\n",
    "\n",
    "    for l in lines:\n",
    "        if c in l:\n",
    "            rename_list = [l.split('\\t')[0].split('.')[1]] + l.split('\\t')[1:]\n",
    "\n",
    "            # print(\"\\t\".join(rename_list))\n",
    "            out.write(\"\\t\".join(rename_list))\n",
    "            # print(l)\n",
    "out.close()\n",
    "f.close()\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
